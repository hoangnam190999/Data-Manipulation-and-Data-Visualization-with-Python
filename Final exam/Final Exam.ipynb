{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d9f9df",
   "metadata": {},
   "source": [
    "# 1.Numpy Array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68616921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(6)\n",
    "arr = np.random.randint(1, 11, (4, 4))\n",
    "print(\"Mảng 4x4 được phát sinh ngẫu nhiên:\")\n",
    "print(arr)\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "for val, count in zip(unique, counts):\n",
    "    print(f\"Giá trị {val} xuất hiện {count} lần\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f61c4c9",
   "metadata": {},
   "source": [
    "# 2. Youtube05-Shakira "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76790f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Read the data and create a text from the CONTENT column. Then normalize the text by removing additional words that are considered meaningless ('waka', 'br', 'amp', 'adf', 'hey', 'hi')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_text(text, stopwords):\n",
    "    pattern = r'\\b(' + '|'.join(stopwords) + r')\\b'\n",
    "    text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def process_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    stopwords = ['waka', 'br', 'amp', 'adf', 'hey', 'hi']\n",
    "\n",
    "    if 'CONTENT' in df.columns:\n",
    "        df['CONTENT_CLEAN'] = df['CONTENT'].astype(str).apply(lambda x: clean_text(x, stopwords))\n",
    "        \n",
    "        \n",
    "        base_name = os.path.basename(file_path)\n",
    "        output_file = os.path.join(os.path.dirname(file_path), f'cleaned_{base_name}')\n",
    "        \n",
    "        \n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"File đã được xử lý và lưu tại: {output_file}\")\n",
    "    else:\n",
    "        print(\"Cột CONTENT không tồn tại trong file.\")\n",
    "\n",
    "\n",
    "file_path = '/Users/hubert/Desktop/thi data/Youtube05-Shakira.csv'  \n",
    "process_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23efbc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Create a Wordcloud chart with the following suggested results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ef725",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "file_path = '/Users/hubert/Desktop/thi data/Youtube05-Shakira.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "comments = \" \".join(data['CONTENT'].astype(str))\n",
    "\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width=800, \n",
    "    height=400, \n",
    "    background_color='black', \n",
    "    colormap='viridis'\n",
    ").generate(comments)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"WordCloud từ nội dung bình luận\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a7a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Given the image file qc.png, create a chart with the suggested results as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7315db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask_path = '/Users/hubert/Desktop/thi data/qc.png'\n",
    "mask_image = np.array(Image.open(mask_path))\n",
    "\n",
    "wordcloud_without_border = WordCloud(\n",
    "    width=800, \n",
    "    height=800, \n",
    "    background_color='white', \n",
    "    colormap='viridis', \n",
    "    mask=mask_image\n",
    ").generate(comments)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(wordcloud_without_border, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8289bba2",
   "metadata": {},
   "source": [
    "# 3.\tData processing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Read data, display general information of 2 data sets: head, tail, info, describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af5dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "courses_file = '/Users/hubert/Desktop/thi data/courses.csv'\n",
    "subjects_file = '/Users/hubert/Desktop/thi data/subjects.csv'\n",
    "\n",
    "courses_data = pd.read_csv(courses_file)\n",
    "subjects_data = pd.read_csv(subjects_file)\n",
    "\n",
    "print(\"=== Thông tin về tập dữ liệu 'courses.csv' ===\")\n",
    "print(\"Head:\")\n",
    "print(courses_data.head(), \"\\n\")\n",
    "print(\"Tail:\")\n",
    "print(courses_data.tail(), \"\\n\")\n",
    "print(\"Info:\")\n",
    "print(courses_data.info(), \"\\n\")\n",
    "print(\"Describe:\")\n",
    "print(courses_data.describe(include='all'), \"\\n\")\n",
    "\n",
    "print(\"=== Thông tin về tập dữ liệu 'subjects.csv' ===\")\n",
    "print(\"Head:\")\n",
    "print(subjects_data.head(), \"\\n\")\n",
    "print(\"Tail:\")\n",
    "print(subjects_data.tail(), \"\\n\")\n",
    "print(\"Info:\")\n",
    "print(subjects_data.info(), \"\\n\")\n",
    "print(\"Describe:\")\n",
    "print(subjects_data.describe(include='all'), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Combine data based on id_sub of courses table and id of subjects table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(courses_data, subjects_data, left_on='id_sub', right_on='id', how='inner')\n",
    "print(\"=== Kết quả sau khi kết hợp dữ liệu ===\")\n",
    "print(merged_data.head(), \"\\n\")\n",
    "print(\"Thông tin tổng quan về bảng dữ liệu kết hợp:\")\n",
    "print(merged_data.info(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eaa555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Delete columns 'course_id','url','id','id_sub','total' in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = merged_data.drop(columns=['course_id', 'url', 'id', 'id_sub', 'total'])\n",
    "print(\"=== Dữ liệu sau khi xóa các cột không cần thiết ===\")\n",
    "print(cleaned_data.head(), \"\\n\")\n",
    "print(\"Thông tin tổng quan về dữ liệu đã làm sạch:\")\n",
    "print(cleaned_data.info(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3cc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Create an additional revenue column equal to the product of the num_subscribers and price columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badfafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['revenue'] = cleaned_data['num_subscribers'] * cleaned_data['price']\n",
    "print(\"=== Dữ liệu sau khi thêm cột 'revenue' ===\")\n",
    "print(cleaned_data.head(), \"\\n\")\n",
    "print(\"Thông tin tổng quan về dữ liệu sau khi thêm cột doanh thu:\")\n",
    "print(cleaned_data.info(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Filter out rows of data with subject ‘Musical Instruments’ and course_title containing ‘Guitarist’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = cleaned_data[\n",
    "    (cleaned_data['subject'] == 'Musical Instruments') & \n",
    "    (cleaned_data['course_title'].str.contains('Guitarist', case=False, na=False))\n",
    "]\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"=== Dữ liệu đã lọc theo yêu cầu  ===\")\n",
    "display(filtered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Shows total enrollments and reviews for each level of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e09b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "summary = cleaned_data.groupby('level').agg(\n",
    "    total_subscribers=('num_subscribers', 'sum'),\n",
    "    total_reviews=('num_reviews', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "print(\"=== Tổng số lượt đăng ký và đánh giá cho từng cấp độ khóa học ===\")\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ba612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Shows average revenue and average price by subject and by course level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "avg_data = cleaned_data.groupby(['subject', 'level']).agg(\n",
    "    avg_revenue=('revenue', 'mean'),\n",
    "    avg_price=('price', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "print(\"=== Trung bình doanh thu và trung bình giá theo môn học và cấp độ khóa học ===\")\n",
    "display(avg_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf93d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Draw a graph showing the price distribution of suggested course levels as shown below and comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "g = sns.FacetGrid(data=cleaned_data, col=\"level\", col_wrap=2, height=4, aspect=1.5, palette=\"dark:coral\")\n",
    "\n",
    "g.map(sns.histplot, \"price\", bins=20, kde=False, color='pink')\n",
    "\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle(\"Phân bố giá tiền theo cấp độ khóa học\", fontsize=16)\n",
    "\n",
    "g.set_axis_labels(\"Price\", \"Count\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4351482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Draw a chart showing the price distribution of course topics as suggested and commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e513f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "cleaned_data = cleaned_data.dropna(subset=['price', 'subject'])\n",
    "\n",
    "cleaned_data['price'] = pd.to_numeric(cleaned_data['price'], errors='coerce')\n",
    "\n",
    "fig = px.box(\n",
    "    cleaned_data,\n",
    "    x=\"price\",\n",
    "    y=\"subject\",\n",
    "    color=\"subject\",\n",
    "    title=\"Biểu đồ Boxplot giá theo môn học\",\n",
    "    labels={\"price\": \"Giá\", \"subject\": \"Môn học\"},\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Draw a chart showing the top 10 highest-grossing courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a73240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "top_10_revenue = cleaned_data.sort_values(by='revenue', ascending=False).head(10)\n",
    "\n",
    "fig = px.bar(\n",
    "    top_10_revenue,\n",
    "    x='revenue',               # Revenue values\n",
    "    y='course_title',          # Course titles\n",
    "    orientation='h',           # Horizontal bar chart\n",
    "    color='revenue',           # Color based on revenue\n",
    "    title='Top 10 Courses with the Highest Revenue',  # Title\n",
    "    labels={'revenue': 'Revenue ($)', 'course_title': 'Course Title'},\n",
    "    color_continuous_scale=px.colors.sequential.Peach  # Pastel color palette\n",
    ")\n",
    "\n",
    "fig.update_layout(yaxis=dict(autorange=\"reversed\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba6f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. Draw a graph showing the ratio of paid and free courses as suggested and commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198735f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "course_counts = cleaned_data['is_paid'].value_counts()\n",
    "\n",
    "labels = ['Free', 'Paid']  # Clarify False = Free, True = Paid\n",
    "sizes = course_counts.values\n",
    "colors = ['#FFC0CB', '#DDA0DD']  # Orange for free, Blue for paid\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(\n",
    "    sizes,\n",
    "    labels=labels,\n",
    "    autopct='%1.2f%%',\n",
    "    colors=colors,\n",
    "    startangle=90,\n",
    "    wedgeprops={'edgecolor': 'black'}\n",
    ")\n",
    "\n",
    "plt.title('Tỉ Lệ Các Khóa Học Trả Phí và Miễn Phí')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60158c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.Draw a graph showing the number of paid and free courses at different levels. What do you think about this graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "level_paid_counts = cleaned_data.groupby(['level', 'is_paid']).size().unstack()\n",
    "\n",
    "ax = level_paid_counts.plot(\n",
    "    kind='bar',\n",
    "    figsize=(8, 6),\n",
    "    color=['#D8BFD8', '#77DD77'],  # Blue for Paid, Orange for Free\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "plt.title('Số Lượng Các Khóa Học Tính Phí và Miễn Phí Theo Cấp Độ', fontsize=14)\n",
    "plt.xlabel('Cấp Độ', fontsize=12)\n",
    "plt.ylabel('Số Lượng Khóa Học', fontsize=12)\n",
    "plt.xticks(rotation=0, fontsize=10)\n",
    "plt.legend(['Tính Phí', 'Miễn Phí'], title='Loại Khóa Học')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361c112",
   "metadata": {},
   "source": [
    "# 4.\tVisualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c91551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1.Read the data World_Power_Consumption.csv, display general information of the data including: head, tail, info, describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4cdd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/hubert/Desktop/thi data/World_Power_Consumption.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Head\n",
    "print(\"### Head (5 dòng đầu):\")\n",
    "display(data.head())\n",
    "\n",
    "# Tail\n",
    "print(\"### Tail (5 dòng cuối):\")\n",
    "display(data.tail())\n",
    "\n",
    "# Info\n",
    "print(\"### Info:\")\n",
    "data_info = pd.DataFrame({\n",
    "    \"Column\": data.columns,\n",
    "    \"Non-Null Count\": [data[col].notnull().sum() for col in data.columns],\n",
    "    \"Dtype\": data.dtypes\n",
    "})\n",
    "display(data_info)\n",
    "\n",
    "# Describe\n",
    "print(\"### Describe:\")\n",
    "display(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b13161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Tạo dataframe mới có 2 cột là Country và Power_Consumption được tách ra từ cột Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d4d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/hubert/Desktop/thi data/World_Power_Consumption.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "new_data = data['Text'].str.extract(r'(?P<Country>[\\w\\s]+)\\s(?P<Power_Consumption>[\\d,]+)')\n",
    "\n",
    "new_data['Country'] = new_data['Country'].str.strip()\n",
    "new_data['Power_Consumption'] = new_data['Power_Consumption'].str.replace(',', '')\n",
    "\n",
    "new_data['Power_Consumption'] = pd.to_numeric(new_data['Power_Consumption'], errors='coerce')\n",
    "\n",
    "print(\"### DataFrame mới:\")\n",
    "display(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d4304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Convert the data type of the Power_Consumption column to int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b630c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/hubert/Desktop/thi data/World_Power_Consumption.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "new_data = data['Text'].str.extract(r'(?P<Country>[\\w\\s]+)\\s(?P<Power_Consumption>[\\d,]+)')\n",
    "\n",
    "new_data['Country'] = new_data['Country'].str.strip()\n",
    "new_data['Power_Consumption'] = new_data['Power_Consumption'].str.replace(',', '')\n",
    "\n",
    "new_data['Power_Consumption'] = pd.to_numeric(new_data['Power_Consumption'], errors='coerce')\n",
    "\n",
    "\n",
    "new_data = new_data.dropna(subset=['Power_Consumption'])\n",
    "\n",
    "\n",
    "new_data['Power_Consumption'] = new_data['Power_Consumption'].astype('int64')\n",
    "\n",
    "\n",
    "print(\"### DataFrame với kiểu dữ liệu đã chuyển đổi:\")\n",
    "display(new_data)\n",
    "\n",
    "print(\"### Thông tin kiểu dữ liệu của DataFrame:\")\n",
    "display(new_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Create a choropleth map according to Power_Consumption of each country using the plotly library as suggested in the following image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5a6633",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/hubert/Desktop/thi data/World_Power_Consumption.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/hubert/Desktop/thi data/World_Power_Consumption.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[1;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      7\u001b[0m new_data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(?P<Country>[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms(?P<Power_Consumption>[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md,]+)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/hubert/Desktop/thi data/World_Power_Consumption.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "file_path = '/Users/hubert/Desktop/thi data/World_Power_Consumption.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "new_data = data['Text'].str.extract(r'(?P<Country>[\\w\\s]+)\\s(?P<Power_Consumption>[\\d,]+)')\n",
    "\n",
    "new_data['Country'] = new_data['Country'].str.strip()\n",
    "new_data['Power_Consumption'] = new_data['Power_Consumption'].str.replace(',', '')\n",
    "new_data['Power_Consumption'] = pd.to_numeric(new_data['Power_Consumption'], errors='coerce')\n",
    "\n",
    "fig = px.choropleth(\n",
    "    new_data,\n",
    "    locations=\"Country\",\n",
    "    locationmode=\"country names\",\n",
    "    color=\"Power_Consumption\",\n",
    "    hover_name=\"Country\",\n",
    "    color_continuous_scale=\"YlOrRd\",\n",
    "    labels={\"Power_Consumption\": \"Power Consumption KWH\"},\n",
    "    title=\"World Power Consumption\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e4e596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
